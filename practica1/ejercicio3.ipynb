{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer perceptron\n",
    "\n",
    "Sea la capa $(P-1)$ con `M` neuronas, la capa $(P)$ con `M` entradas y `N` neuronas y la capa $(P+1)$ con `K` neuronas.\n",
    "\n",
    "## Pasada forward\n",
    "\n",
    "La entrada es la salida de la capa precedente:\n",
    "$\\underset{M \\times 1}{\\bm{x}^{(P)}} = \\bm{y}^{(P-1)} = \\left[ y_1^{(P-1)} \\, y_2^{(P-1)} \\, \\dots \\, y_i^{(P-1)} \\, \\dots \\, y_M^{(P-1)} \\right]^{\\normalsize T}$\n",
    "\n",
    "> Caso especial: primer capa\n",
    "$\\underset{M \\times 1}{\\bm{x}^{(\\mathrm{I})}} = \\bm{x} = \\left[ x_1 \\, x_2 \\, \\dots \\, x_i \\, \\dots \\, x_M \\right]^{\\normalsize T}$\n",
    "\n",
    "La matriz de pesos:\n",
    "$\\underset{{N \\times (M+1)}}{\\bm{W}^{(P)}} = \\begin{bmatrix}\n",
    "\\blue{w_{10}^{(P)}} & w_{11}^{(P)} & w_{12}^{(P)} & \\dots & w_{1i}^{(P)} & \\dots & w_{1M}^{(P)} \\\\\n",
    "\\blue{w_{20}^{(P)}} & w_{21}^{(P)} & w_{22}^{(P)} & \\dots & w_{2i}^{(P)} & \\dots & w_{2M}^{(P)} \\\\\n",
    "\\vdots & \\vdots& \\vdots & & \\vdots & & \\vdots \\\\\n",
    "\\blue{w_{j0}^{(P)}} & w_{j1}^{(P)} & w_{j2}^{(P)} & \\dots & w_{ji}^{(P)} & \\dots & w_{jM}^{(P)} \\\\\n",
    "\\vdots & \\vdots& \\vdots & & \\vdots & & \\vdots \\\\\n",
    "\\blue{w_{N0}^{(P)}} & w_{N1}^{(P)} & w_{N2}^{(P)} & \\dots & w_{Ni}^{(P)} & \\dots & w_{NM}^{(P)}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "Para el cálculo de la salida se agrega el bias a la entrada en la primer columna: $\\underset{(M+1) \\times 1}{\\bm{\\hat{x}}^{(P)}} = \\left[ \\blue{-1} \\, y_1^{(P-1)} \\, y_2^{(P-1)} \\, \\dots \\, y_i^{(P-1)} \\, \\dots \\, y_M^{(P-1)} \\right]^{\\normalsize T}$\n",
    "\n",
    "La salida se define como el producto matricial entre la matriz de pesos y la entrada:\n",
    "\n",
    "$\\underset{N \\times 1}{\\bm{y}^{(P)}} = \\left\\langle \\bm{W}^{(P)} \\, \\bm{\\hat{x}}^{(P)} \\right\\rangle = \\begin{bmatrix}\n",
    "\\blue{-w_{10}^{(P)}} + y_1^{(P-1)} w_{11}^{(P)} + y_2^{(P-1)} w_{12}^{(P)} + \\dots + y_i^{(P-1)} w_{1i}^{(P)} + \\dots + y_M^{(P-1)} w_{1M}^{(P)} \\\\\n",
    "\\blue{-w_{20}^{(P)}} + y_1^{(P-1)} w_{21}^{(P)} + y_2^{(P-1)} w_{22}^{(P)} + \\dots + y_i^{(P-1)} w_{2i}^{(P)} + \\dots + y_M^{(P-1)} w_{2M}^{(P)} \\\\\n",
    "\\vdots \\\\\n",
    "\\blue{-w_{j0}^{(P)}} + y_1^{(P-1)} w_{j1}^{(P)} + y_2^{(P-1)} w_{j2}^{(P)} + \\dots + y_i^{(P-1)} w_{ji}^{(P)} + \\dots + y_M^{(P-1)} w_{jM}^{(P)} \\\\\n",
    "\\vdots \\\\\n",
    "\\blue{-w_{N0}^{(P)}} + y_1^{(P-1)} w_{N1}^{(P)} + y_2^{(P-1)} w_{N2}^{(P)} + \\dots + y_i^{(P-1)} w_{Ni}^{(P)} + \\dots + y_M^{(P-1)} w_{NM}^{(P)} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "## Pasada backward\n",
    "\n",
    "Gradiente de error instantaneo de la capa siguiente:\n",
    "$\\underset{K \\times 1}{\\bm{\\delta}^{(P+1)}} = \\left[ \\delta_1^{(P+1)} \\, \\delta_2^{(P+1)} \\, \\dots \\, \\delta_i^{(P+1)} \\, \\dots \\, \\delta_K^{(P+1)} \\right]^{\\large T}$\n",
    "\n",
    "Sea la matriz de pesos de la capa siguiente:\n",
    "$\\underset{{K \\times N}}{\\bm{W}^{(P+1)}} = \\begin{bmatrix}\n",
    "\\blue{w_{10}^{(P+1)}} & w_{11}^{(P+1)} & w_{12}^{(P+1)} & \\dots & w_{1i}^{(P+1)} & \\dots & w_{1N}^{(P+1)} \\\\\n",
    "\\blue{w_{20}^{(P+1)}} & w_{21}^{(P+1)} & w_{22}^{(P+1)} & \\dots & w_{2i}^{(P+1)} & \\dots & w_{2N}^{(P+1)} \\\\\n",
    "\\vdots & \\vdots & \\vdots& & \\vdots & & \\vdots \\\\\n",
    "\\blue{w_{j0}^{(P+1)}} & w_{j1}^{(P+1)} & w_{j2}^{(P+1)} & \\dots & w_{ji}^{(P+1)} & \\dots & w_{jN}^{(P+1)} \\\\\n",
    "\\vdots & \\vdots & \\vdots& & \\vdots & & \\vdots \\\\\n",
    "\\blue{w_{K0}^{(P+1)}} & w_{K1}^{(P+1)} & w_{K2}^{(P+1)} & \\dots & w_{Ki}^{(P+1)} & \\dots & w_{KN}^{(P+1)}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "se elimina la columna de bias y se transpone:\n",
    "$\\underset{{N \\times K}}{\\bm{\\hat{W}}^{(P+1)}} = \\begin{bmatrix}\n",
    "w_{11}^{(P+1)} & w_{21}^{(P+1)} & \\dots & w_{j1}^{(P+1)} & \\dots & w_{K1}^{(P+1)} \\\\\n",
    "w_{12}^{(P+1)} & w_{22}^{(P+1)} & \\dots & w_{j2}^{(P+1)} & \\dots & w_{K2}^{(P+1)} \\\\\n",
    "\\vdots & \\vdots&  & \\vdots & & \\vdots \\\\\n",
    "w_{1i}^{(P+1)} & w_{2i}^{(P+1)} & \\dots & w_{ji}^{(P+1)} & \\dots & w_{Ki}^{(P+1)} \\\\\n",
    "\\vdots & \\vdots&  & \\vdots & & \\vdots \\\\\n",
    "w_{1N}^{(P+1)} & w_{2N}^{(P+1)} & \\dots & w_{jN}^{(P+1)} & \\dots & w_{KN}^{(P+1)}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "El gradiente de error local se define como el producto matricial entre esta matriz $\\bm{\\hat{W}}^{(P+1)}$ y el gradiente de error de esa misma capa $\\bm{\\delta}^{(P+1)}$:\n",
    "\n",
    "$\\underset{N \\times 1}{\\bm{\\delta}^{(P)}} = \\frac{1}{2} \\left\\langle \\bm{\\hat{W}}^{(P+1)} \\, \\bm{\\delta}^{(P+1)} \\right\\rangle \\odot (1 + {\\bm{y}^{(P)}}) \\odot (1 - {\\bm{y}^{(P)}}) = \\frac{1}{2} \\begin{bmatrix}\n",
    "\\delta_1^{(P+1)} w_{11}^{(P+1)} + \\delta_2^{(P+1)} w_{21}^{(P+1)} + \\dots + \\delta_i^{(P+1)} w_{j1}^{(P+1)} + \\dots + \\delta_K^{(P+1)} w_{K1}^{(P+1)} \\\\\n",
    "\\delta_1^{(P+1)} w_{12}^{(P+1)} + \\delta_2^{(P+1)} w_{22}^{(P+1)} + \\dots + \\delta_i^{(P+1)} w_{j2}^{(P+1)} + \\dots + \\delta_K^{(P+1)} w_{K2}^{(P+1)} \\\\\n",
    "\\vdots \\\\\n",
    "\\delta_1^{(P+1)} w_{1i}^{(P+1)} + \\delta_2^{(P+1)} w_{2i}^{(P+1)} + \\dots + \\delta_i^{(P+1)} w_{ji}^{(P+1)} + \\dots + \\delta_K^{(P+1)} w_{Ki}^{(P+1)} \\\\\n",
    "\\vdots \\\\\n",
    "\\delta_1^{(P+1)} w_{1N}^{(P+1)} + \\delta_2^{(P+1)} w_{2N}^{(P+1)} + \\dots + \\delta_i^{(P+1)} w_{jN}^{(P+1)} + \\dots + \\delta_K^{(P+1)} w_{KN}^{(P+1)} \n",
    "\\end{bmatrix} \\odot (1 + {\\bm{y}^{(P)}}) \\odot (1 - {\\bm{y}^{(P)}})$\n",
    "\n",
    "> Caso especial: última capa $H$ de `L` neuronas, sea la salida deseada $\\underset{L \\times 1}{\\bm{y_d}} = \\left[ {y_d}_1 \\, {y_d}_2 \\, \\dots \\, {y_d}_i \\, \\dots \\, {y_d}_L \\right]^{\\normalsize T}$\n",
    ">\n",
    "> Según leandro:\n",
    "$\\bm{\\delta}^{(H)} = \\frac{1}{2} {\\left( \\bm{y_d} - \\bm{y}^{(H)} \\right)}^2 \\, (1 + {\\bm{y}^{(H)}}) \\odot (1 - {\\bm{y}^{(H)}})$\n",
    ">\n",
    "> Lo que me parece:\n",
    "$\\bm{\\delta}^{(H)} = \\frac{1}{2} \\left( \\bm{y_d} - \\bm{y}^{(H)} \\right) \\odot (1 + {\\bm{y}^{(H)}}) \\odot (1 - {\\bm{y}^{(H)}})$\n",
    "\n",
    "## Actualización de pesos\n",
    "\n",
    "Sea $\\bm{\\hat{x}}^{(P)}$ utilizada para calcular la salida y el gradiente de error instantaneo local $\\bm{\\delta}^{(P)}$, la matriz de ajuste de pesos se define como:\n",
    "\n",
    "$\\underset{{N \\times (M+1)}}{\\bm{\\Delta W}^{(P)}} = \\mu \\, \\bm{\\delta}^{(P)} \\, {\\bm{\\hat{x}}^{(P)}}^{T} = \\mu \\, \\begin{bmatrix}\n",
    "\\blue{-\\delta_1^{(P)}} & \\delta_1^{(P)} y_1^{(P-1)} & \\delta_1^{(P)} y_2^{(P-1)} & \\dots & \\delta_1^{(P)} y_i^{(P-1)} & \\dots & \\delta_1^{(P)} y_M^{(P-1)} \\\\\n",
    "\\blue{-\\delta_2^{(P)}} & \\delta_2^{(P)} y_1^{(P-1)} & \\delta_2^{(P)} y_2^{(P-1)} & \\dots & \\delta_2^{(P)} y_i^{(P-1)} & \\dots & \\delta_2^{(P)} y_M^{(P-1)} \\\\\n",
    "\\vdots & \\vdots& \\vdots & & \\vdots & & \\vdots \\\\\n",
    "\\blue{-\\delta_i^{(P)}} & \\delta_i^{(P)} y_1^{(P-1)} & \\delta_i^{(P)} y_2^{(P-1)} & \\dots & \\delta_i^{(P)} y_i^{(P-1)} & \\dots & \\delta_i^{(P)} y_M^{(P-1)} \\\\\n",
    "\\vdots & \\vdots& \\vdots & & \\vdots & & \\vdots \\\\\n",
    "\\blue{-\\delta_N^{(P)}} & \\delta_N^{(P)} y_1^{(P-1)} & \\delta_N^{(P)} y_2^{(P-1)} & \\dots & \\delta_N^{(P)} y_i^{(P-1)} & \\dots & \\delta_N^{(P)}y_M^{(P-1)} \n",
    "\\end{bmatrix}$\n",
    "\n",
    "Nuevos pesos $\\bm{W}^{(P)}_{(n+1)} = \\bm{W}^{(P)}_{(n)} + \\bm{\\Delta W}^{(P)}_{(n)}$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
