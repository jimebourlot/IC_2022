{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1\n",
    "\n",
    "Codifique el algoritmo de entrenamiento para una red neuronal con RBF y pruebe su implementación en la resolución del problema `xor`, empleando los datos de la guía anterior.\n",
    "Diseñe una red RBF para resolver el problema Iris (`irisbin.csv`), considerando una cantidad de parámetros similar a la red MLP de la guía anterior. \n",
    "Luego compare la velocidad de entrenamiento y el porcentaje final de clasificación obtenido con ambas arquitecturas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_particiones(filename, n, p_test):\n",
    "    ds = np.genfromtxt(filename, delimiter=',')\n",
    "    n_test = int(ds.shape[0] * p_test)\n",
    "    n_train = ds.shape[0] - n_test\n",
    "    M_test = np.zeros((n,n_test),dtype = int)\n",
    "    M_train = np.zeros((n, n_train),dtype = int)\n",
    "\n",
    "    for i in range(n):\n",
    "        idx=np.random.choice(range(ds.shape[0]),ds.shape[0],replace = False)\n",
    "        idx_test = idx[0:n_test]\n",
    "        idx_train = idx[n_test:ds.shape[0]]\n",
    "        M_test[i] = idx_test\n",
    "        M_train[i] = idx_train\n",
    "    \n",
    "    return (ds, M_test, M_train)\n",
    "\n",
    "def sigmoidea(x):\n",
    "    return np.divide(2, (1 + np.exp(-1 * x))) - 1\n",
    "\n",
    "class layer:\n",
    "    def __init__(self, NNeurons, NInputs):\n",
    "        # Almacenar la dimensión de entrada y cantidad de neuronas\n",
    "        self.neurons_ = NNeurons\n",
    "        self.inputs_ = NInputs\n",
    "\n",
    "        # Inicializar la matriz de pesos de N x M con valores aleatorios\n",
    "        # con una distribución normal centrada en 0 y norma < 0.5 aprox \n",
    "        # self.w = np.random.normal(loc = 0, scale = 0.15, size = (NNeurons, NInputs))\n",
    "        self.w = rng.random((NNeurons, NInputs))\n",
    "        \n",
    "    def eval(self, x):\n",
    "        # Comprobar que la dimension de la entrada es igual a la incializada \n",
    "        assert x.shape[0] == self.inputs_, \\\n",
    "            f\"La entrada de dimensión {x.shape[0]} no coincide con la declarada {self.inputs_}\"\n",
    "\n",
    "        # Producto interno entre la entrada y los pesos\n",
    "        y = np.dot(self.w, x)\n",
    "        \n",
    "        # No linealidad\n",
    "        z = sigmoidea(y)\n",
    "        return z\n",
    "\n",
    "class MultiLayerPerceptron:\n",
    "    def __init__(self, neuronsPerLayer, NInputs):\n",
    "        self.neuronsPerLayer_ = neuronsPerLayer\n",
    "        self.NInputs = NInputs\n",
    "\n",
    "        # La red estará representada como un arreglo de capas\n",
    "        self.network_ = []\n",
    "        \n",
    "        # Auxiliar para definiar la cantidad de entradas de cada capa\n",
    "        # La primera coincide con la entrada de la red\n",
    "        NInputs_aux = NInputs\n",
    "\n",
    "        # Para cada capa representada como el número de neuronas\n",
    "        for layerNeurons in neuronsPerLayer:\n",
    "            # Se crea una capa en base a la cantidad de salidas de la capa\n",
    "            # anterior + 1 (el bias) y con el número de neuronas indicado\n",
    "            self.network_.append(layer(layerNeurons, NInputs_aux + 1))\n",
    "            \n",
    "            # Adelantar la cantidad de entradas para la próxima capa\n",
    "            NInputs_aux = layerNeurons\n",
    "\n",
    "        # Arreglo auxiliar para almacenar los gradientes instantáneos\n",
    "        self.grad_ = []\n",
    "    \n",
    "    def eval(self, input):\n",
    "        # Comprobar que la dimension de la entrada es igual a la incializada \n",
    "        assert input.shape[0] == self.NInputs, \\\n",
    "            f\"La entrada de dimensión {input.shape[0]} no coincide con la declarada {self.NInputs}\"\n",
    "\n",
    "        # La salida de cada capa será acumulada en un arreglo\n",
    "        # que es devuelto para luego utilizar en la etapa de train\n",
    "        y = [input]\n",
    "        \n",
    "        for i in range(len(self.network_)): # Para cada capa en la red\n",
    "            # Agregar el bias a la entrada de la capa i (como primer componente)\n",
    "            x_ = np.hstack((-1, y[i]))\n",
    "\n",
    "            # Calcular la salida de la capa i\n",
    "            y_ = self.network_[i].eval(x_)\n",
    "            \n",
    "            # Agregar la salida al arreglo, que será la entrada de la siguiente\n",
    "            y.append(y_)\n",
    "        \n",
    "        # Devolver la salida como tal, y las salidas intermedias de cada capa\n",
    "        return (y[-1], y)\n",
    "\n",
    "    def backward(self, y, yd):\n",
    "        # Comprobar que la dimension de la salida calculada es igual a la de la deseada \n",
    "        assert yd.shape[0] == y[-1].shape[0], \\\n",
    "            f\"La dimensión de la salida deseada ({yd.shape[0]}) no coincide con la calculada ({y[-1].shape[0]})\"\n",
    "        \n",
    "        # Comprobar que la dimension de la salida deseada es igual a la cantidad de neuronas de salida \n",
    "        assert yd.shape[0] == self.neuronsPerLayer_[-1], \\\n",
    "            f\"La dimensión de la salida deseada ({yd.shape[0]}) no coincide con la capa de salida ({self.neuronsPerLayer_[-1]})\"\n",
    "\n",
    "        # Se calcula el error entre la salida de la red (último componente de y)\n",
    "        # y la salida deseada (la dimensión será la cantidad de neuronas a la salida)\n",
    "        error_ = yd - y[-1]\n",
    "\n",
    "        # Reiniciar el vector de gradientes instantaneos\n",
    "        self.grad_ = []\n",
    "\n",
    "        # Calcular el gradiente de la capa de salida y guardarlo\n",
    "        self.grad_.append((np.multiply(error_, np.multiply((1 + y[-1]), (1 - y[-1])))) * 0.5)\n",
    "        \n",
    "        # Recorriendo las capas desde la penultima hacia la de entrada\n",
    "        for i in range(len(self.network_)-1,0,-1):\n",
    "            # De la capa siguiente (en el orden forward), tomar la matriz de pesos\n",
    "            # sin la columna de pesos asociados al bias, y transponerla (wT_)\n",
    "            wT_ = self.network_[i].w[:,1:].T\n",
    "\n",
    "            # Calcular el gradiente local instantaneo como el producto interno entre\n",
    "            # wT_ y el gradiente de error local de esa misma capa (la siguiente en orden forward)\n",
    "            # en lo que se conoce como retropropagación del error\n",
    "            # TODO: chequear el indexado\n",
    "            d_ = np.dot(wT_, self.grad_[len(self.network_)-1-i])\n",
    "\n",
    "            # Luego multiplicar por la derivada de la sigmoidea\n",
    "            g_ = (np.multiply(d_, np.multiply((1 + y[i]), (1 - y[i])))) * 0.5\n",
    "            \n",
    "            # Agregar al arreglo de gradientes\n",
    "            self.grad_.append(g_)\n",
    "\n",
    "    def update(self, y, lr):\n",
    "        # Actualización de pesos para cada capa\n",
    "        for i in range(len(self.network_)):\n",
    "            # Se calcula el producto entre el gradiente local instantáneo de la capa \n",
    "            # con la entrada de la capa (con bias), esto multiplicado por la tasa\n",
    "            # de aprendizaje resulta en la matriz de actualización de pesos\n",
    "            Dw_ = lr * np.outer(self.grad_[-(i+1)], np.hstack((-1, y[i])))\n",
    "            \n",
    "            # Los nuevos pesos se calculan como el Delta + los pesos \"viejos\"\n",
    "            self.network_[i].w = np.add(self.network_[i].w, Dw_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(x, k):\n",
    "    # k define la cantidad de grupos\n",
    "    # se toman k grupos y se le asigna a cada patrón un grupo aleatorio\n",
    "    group_idx = np.repeat(range(k),np.ceil(x.shape[0]/k))[:x.shape[0]]\n",
    "    \n",
    "    \n",
    "        \n",
    "    vec_reasig = np.zeros(x.shape[0])\n",
    "    cant_it = 0\n",
    "    means_vec = np.zeros((k, x.shape[1]))\n",
    "    stdev_vec = np.zeros((k, x.shape[1]))\n",
    "\n",
    "    # mientras se hayan hecho reasignaciones (sale cuando todos son verdaderos -> no hubo reasignaciones)\n",
    "    while vec_reasig.all() != True:\n",
    "        cant_it += 1\n",
    "        \n",
    "        # se calculan los centroides de cada grupo\n",
    "        for i in range(k):\n",
    "            group = x[group_idx == i]\n",
    "            # si hay algo en el grupo\n",
    "            if(group.shape[0] > 0):\n",
    "                means_vec[i] =  np.mean(group, axis = 0)\n",
    "                # if(group.shape[0] > 1):\n",
    "                #     stdev_vec[i] = np.std(group, axis = 0)\n",
    "\n",
    "        \n",
    "        # por cada patron\n",
    "        for i, pattern in enumerate(x):\n",
    "            dist_vec = []\n",
    "            for i_group in range(k):\n",
    "                # vector distancias entre el patron y los centroides\n",
    "                dist_vec.append(np.linalg.norm(pattern - means_vec[i_group]))\n",
    "            # índice del centroide que tiene menor distancia\n",
    "            idx_min = np.argmin(dist_vec)\n",
    "            # reasignación de grupo si es necesario\n",
    "            if (group_idx[i] != idx_min):\n",
    "                vec_reasig[i] == False\n",
    "                group_idx[i] = idx_min\n",
    "            # si no hay reasignación se pone en verdadero\n",
    "            else:\n",
    "                vec_reasig[i] = True\n",
    "    \n",
    "    for i in range(k):\n",
    "        group = x[group_idx == i]\n",
    "        # si hay algo en el grupo\n",
    "        if(group.shape[0] > 1):\n",
    "            stdev_vec[i] = np.std(group, axis = 0)\n",
    "    \n",
    "    print(np.histogram(group_idx,range(k+1)))\n",
    "            \n",
    "    return group_idx, stdev_vec, means_vec, cant_it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_gaussian(x, c, mu):\n",
    "    # desvío fijo, igual al promedio entre el desvío de cada dimensión\n",
    "    mu = np.ones_like(mu) * np.mean(mu)\n",
    "    d_ = np.subtract(x, c)\n",
    "    c_ = np.diag(1 / mu)\\\n",
    "    # HAY QUE CHECKEAR LO DE LA DESVIACION POR QUE\n",
    "    #PONIENDOLA FIJA QUE ES LA SALVEDAD MAS SIMPLEMQUE DIJO DIPERSIA EL CODIGO ANDA.\n",
    "    y = np.exp(-0.5 * np.dot(np.dot(d_.T, 1), d_))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (6,) and (5,) not aligned: 6 (dim 0) != 5 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\ignac\\OneDrive\\Escritorio\\FICH\\4to\\Inteligencia Computacional\\IC_2022\\practica2\\ejercicio1.ipynb Celda 6\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ignac/OneDrive/Escritorio/FICH/4to/Inteligencia%20Computacional/IC_2022/practica2/ejercicio1.ipynb#X26sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m d\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m,\u001b[39m6\u001b[39m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/ignac/OneDrive/Escritorio/FICH/4to/Inteligencia%20Computacional/IC_2022/practica2/ejercicio1.ipynb#X26sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m mu \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mones_like(mu) \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mmean(mu)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/ignac/OneDrive/Escritorio/FICH/4to/Inteligencia%20Computacional/IC_2022/practica2/ejercicio1.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39;49mdot(d\u001b[39m.\u001b[39;49mT,mu))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (6,) and (5,) not aligned: 6 (dim 0) != 5 (dim 0)"
     ]
    }
   ],
   "source": [
    "mu=[1,2,3,4,5]\n",
    "d=np.array([1,2,3,4,5,6])\n",
    "mu = np.ones_like(mu) * np.mean(mu)\n",
    "print(np.dot(d.T,mu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, testPartitionsIdx, trainPartitionsIdx  =  generar_particiones('gtp2datos/XOR_trn.csv', 1, 0.2)\n",
    "\n",
    "# Separar patrones para validación\n",
    "# Cantidad de patrones para entrenamiento\n",
    "NPatternsTrain = trainPartitionsIdx.shape[1]\n",
    "# Cantidad de patrones a separar para validación\n",
    "NPatternsValidation = 100\n",
    "#variable que indica el numero de salidas que tiene el dataset\n",
    "y_num=1\n",
    "# Generar el vector de entradas para entrenamiento y validación (solo una partición)\n",
    "#X_val = ds[trainPartitionsIdx[0, :NPatternsValidation], :-1]\n",
    "X = ds[trainPartitionsIdx[0], :-y_num]\n",
    "# Generar el vector de salida deseada para entrenamiento y validación\n",
    "#Yd_val = ds[trainPartitionsIdx[0, :NPatternsValidation], -1]\n",
    "Yd = ds[trainPartitionsIdx[0], -y_num].reshape((-1,y_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([389, 284, 119,   0, 406,   0, 402,   0,   0,   0], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]))\n"
     ]
    }
   ],
   "source": [
    "k = 10          # cantidad de grupos / RBF\n",
    "\n",
    "# [puede ser que queden grupos vacíos?]\n",
    "idx_groups, std_vec, means_vec, cant_it = kMeans(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 360x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig1 = plt.figure(figsize=(5, 4), tight_layout=True)\n",
    "# fig1.suptitle('Recta $w_1 x + w_2 y - w_0 = 0$',  fontsize=11)\n",
    "fig1_ax = fig1.add_subplot(autoscale_on=False, xlim=(-1.5, 1.5), ylim=(-1.5, 1.5))\n",
    "fig1_ax.set_aspect('equal')\n",
    "fig1_ax.grid()\n",
    "\n",
    "# Patrones\n",
    "x_x = X[:,0]\n",
    "x_y = X[:,1]\n",
    "x_color = np.where(Yd[:,0] == 1, 'C0', 'C2')\n",
    "fig1_ax.scatter(x_x, x_y, c=x_color, s=5, marker='.')\n",
    "\n",
    "# k-means\n",
    "fig1_ax.scatter(means_vec[:,0], means_vec[:,1], marker='x', c='C3')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignac\\AppData\\Local\\Temp\\ipykernel_25372\\2994186229.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c_ = np.diag(1 / mu)\n"
     ]
    }
   ],
   "source": [
    "# salidas de las RBF -> entradas del mlp\n",
    "mlp_in = np.zeros((X.shape[0], k))\n",
    "\n",
    "# por cada patrón, se calcula la salida de la capa radial pasando por la RBF\n",
    "for i, pattern in enumerate(X):\n",
    "\n",
    "    _aux = [f_gaussian(pattern, _mean, _mu) for (_mean, _mu) in zip(means_vec, std_vec)]\n",
    "    mlp_in[i] = _aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 10)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perceptrón\n",
    "layerStack = np.array([y_num])\n",
    "perceptron_simple = MultiLayerPerceptron(layerStack, k)\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "NEpoch = 5000           # Cantidad de épocas máximas (anterior 2000)\n",
    "errorThr = 0.2         # Umbral de error para finalizar (anterior 0.005)\n",
    "lr = 5E-3                # Tasa de aprendizaje (anterior 8E-3)\n",
    "\n",
    "mlp_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizó en la época 1 con una tasa de error de 0.0\n"
     ]
    }
   ],
   "source": [
    "# Arreglos auxiliares para guardar la evolución del error de la red\n",
    "errorRatePerEpoch = []\n",
    "MMSEPerEpoch = []\n",
    "\n",
    "for epoch in range(NEpoch): # Para cada época\n",
    "    for pattern, yd in zip(mlp_in, Yd): # Para cada patrón en la partición\n",
    "        # Calcular la salida según los pesos actuales (pasada hacia adelante)\n",
    "        (_, y_) = perceptron_simple.eval(pattern)\n",
    "        #print(f'salida{_}={y_}')\n",
    "\n",
    "        # Realizar la propagación hacia atrás donde se calculan los gradientes\n",
    "        # instantáneos (pasada hacia atrás)\n",
    "        perceptron_simple.backward(y_, yd)\n",
    "        \n",
    "        # Actualizar los pesos de la red\n",
    "        perceptron_simple.update(y_, lr)\n",
    "    \n",
    "    # Para la validación se utilizarán solo algunos patrones y se calculará una\n",
    "    # tasa de error, si esta es menor al umbral, se termina el proceso de entrenamiento\n",
    "    # A la vez, se calculará el error cuadrático medio para tener una evolución\n",
    "    # de dicha variable a lo largo de las épocas\n",
    "    errorsAccum_ = 0    # Acumulador de errores\n",
    "    SEAcumm_ = 0        # Acumulador error cuadrático\n",
    "\n",
    "    # [valido con todos los patrones]\n",
    "    for patron, yd in zip(mlp_in, Yd):\n",
    "        # Evaluar el patron\n",
    "        (z_, _) = perceptron_simple.eval(patron)\n",
    "        \n",
    "        #CODIFICACION\n",
    "        y_ = -1 if (z_[-1] < 0) else 1\n",
    "  \n",
    "        \n",
    "        # Comparación con la salida deseada y acumulación de errores\n",
    "        errorsAccum_ += int(np.any(np.not_equal(y_, yd)))\n",
    "  \n",
    "        # Cálculo del error cuadrático y acumulación\n",
    "        SEAcumm_ += np.sum(np.square(yd - z_))\n",
    "\n",
    "    # Tasa de error: errores / patrones evaluados\n",
    "    errorRate_ = (errorsAccum_/X.shape[0])\n",
    "    # Guardar la tasa de error de1000 la época\n",
    "    errorRatePerEpoch= np.append(errorRatePerEpoch, [errorRate_])\n",
    "    \n",
    "    # Calcular el error cuadrático medio promedio: MSE / patrones evaluados\n",
    "    MSEMean_= (SEAcumm_/X.shape[0])\n",
    "    # Guardar el error cuadrático medio promedio de la época\n",
    "    MMSEPerEpoch = np.append(MMSEPerEpoch, MSEMean_)\n",
    "\n",
    "    # Si la tasa de error es menor al umbral, termina el proceso de entrenamiento\n",
    "    if (errorRate_ < errorThr):\n",
    "        break\n",
    "\n",
    "    # Cada 100 épocas mostrar el error\n",
    "    # if (epoch+1) % 100 == 0:\n",
    "    #     print(f'Época {epoch+1}: tasa de error de {errorRatePerEpoch[-1]} | MSE promedio {MMSEPerEpoch[-1]}')\n",
    "   \n",
    "# Imprimir información acerca del entrenamiento\n",
    "print(f'Finalizó en la época {epoch+1} con una tasa de error de {errorRatePerEpoch[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfica de la tasa de error por época junto con el MSE promedio por época\n",
    "epochs = errorRatePerEpoch.shape[0]\n",
    "xx_ = range(epochs)\n",
    "\n",
    "fig1, fig1_ax = plt.subplots()\n",
    "fig1.suptitle(\"Tasa de error y MSE promedio por épocas\")\n",
    "fig1_ax.set_xlabel('Épocas')\n",
    "fig1_ax.xaxis.set_major_locator(MaxNLocator(integer=True)) # Solo ticks en enteros\n",
    "fig1_ax.grid()\n",
    "fig1_ax.set_ylabel('Tasa de error')\n",
    "\n",
    "fig1_plot1 = fig1_ax.plot(xx_, errorRatePerEpoch, label='Tasa de error')\n",
    "\n",
    "fig1_ax2 = fig1_ax.twinx()\n",
    "fig1_plot2 = fig1_ax2.plot(xx_, MMSEPerEpoch, label='MSE promedio', color='C2')\n",
    "fig1_ax2.set_ylabel('MSE promedio')\n",
    "\n",
    "# added these three lines\n",
    "lns = fig1_plot1+fig1_plot2\n",
    "labs = [l.get_label() for l in lns]\n",
    "fig1_ax.legend(lns, labs, loc=0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tasa de error en prueba 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignac\\AppData\\Local\\Temp\\ipykernel_25372\\2994186229.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c_ = np.diag(1 / mu)\n"
     ]
    }
   ],
   "source": [
    "# Procesar los datos para test\n",
    "# Generar el vector de entradas para test\n",
    "XTest = ds[testPartitionsIdx[0,:], :-1]\n",
    "# Generar el vector de salida deseada para test\n",
    "YdTest = ds[testPartitionsIdx[0,:], -1]\n",
    "\n",
    "mlp_in_test = np.zeros((XTest.shape[0], k))\n",
    "\n",
    "# por cada patrón, se calcula la salida de la capa radial pasando por la RBF\n",
    "for i, pattern in enumerate(XTest):\n",
    "    _aux = [f_gaussian(pattern, _mean, _mu) for (_mean, _mu) in zip(means_vec, std_vec)]\n",
    "    mlp_in_test[i] = _aux / np.linalg.norm(_aux)\n",
    "\n",
    "errorsAccum_ = 0     # Acumulador de errores\n",
    "for pattern, yd in zip(mlp_in_test, YdTest):\n",
    "    # Calcular la salida\n",
    "    (z_, _) = perceptron_simple.eval(pattern)\n",
    "    \n",
    "    # Codificación de la salida\n",
    "    y_ = -1 if (z_[-1] < 0) else 1\n",
    "    \n",
    "    # Comparación con la salida deseada y acumulación de errores\n",
    "    errorsAccum_ += int(y_ != yd)\n",
    "\n",
    "print(f'Tasa de error en prueba {errorsAccum_ / XTest.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# irisbin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds, testPartitionsIdx, trainPartitionsIdx  =  generar_particiones('gtp2datos/irisbin.csv', 1, 0.2)\n",
    "# Separar patrones para validación\n",
    "# Cantidad de patrones para entrenamiento\n",
    "NPatternsTrain = trainPartitionsIdx.shape[1]\n",
    "# Cantidad de patrones a separar para validación\n",
    "NPatternsValidation = 100\n",
    "#variable que indica la cantidad de salidas en el dataset\n",
    "y_num=3\n",
    "\n",
    "\n",
    "#NO ESTAREMOS CAMBIANDO EL DATA SET ACA?\n",
    "\n",
    "# Generar el vector de entradas para entrenamiento y validación (solo una partición)\n",
    "#X_val = ds[trainPartitionsIdx[0, :NPatternsValidation], :-1]\n",
    "X = ds[trainPartitionsIdx[0], :-y_num]\n",
    "# Generar el vector de salida deseada para entrenamiento y validación\n",
    "#Yd_val = ds[trainPartitionsIdx[0, :NPatternsValidation], -1]\n",
    "Yd = ds[trainPartitionsIdx[0], -y_num:]\n",
    "\n",
    "# X = ds[trainPartitionsIdx[0], :-y_num]\n",
    "# # Generar el vector de salida deseada para entrenamiento y validación\n",
    "# #Yd_val = ds[trainPartitionsIdx[0, :NPatternsValidation], -1]\n",
    "# Yd = ds[trainPartitionsIdx[0], -y_num].reshape((-1,y_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0,  1,  0,  8, 13, 31, 14,  1,  0,  1,  7,  0,  0,  0,  0, 16, 20,\n",
      "        8,  0,  0], dtype=int64), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
      "       17, 18, 19, 20]))\n"
     ]
    }
   ],
   "source": [
    "k = 20         # cantidad de grupos / RBF\n",
    "\n",
    "# [puede ser que queden grupos vacíos?]\n",
    "idx_groups, std_vec, means_vec, cant_it = kMeans(X, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ignac\\AppData\\Local\\Temp\\ipykernel_25372\\2994186229.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c_ = np.diag(1 / mu)\n"
     ]
    }
   ],
   "source": [
    "# salidas de las RBF -> entradas del mlp\n",
    "mlp_in = np.zeros((X.shape[0], k))\n",
    "\n",
    "# por cada patrón, se calcula la salida de la capa radial pasando por la RBF\n",
    "for i, pattern in enumerate(X):\n",
    "\n",
    "    _aux = [f_gaussian(pattern, _mean, _mu) for (_mean, _mu) in zip(means_vec, std_vec)]\n",
    "    mlp_in[i] = _aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 20)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#perceptrón\n",
    "layerStack = np.array([y_num])\n",
    "perceptron_simple = MultiLayerPerceptron(layerStack, k)\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "NEpoch = 5000           # Cantidad de épocas máximas (anterior 2000)\n",
    "errorThr = 0.01         # Umbral de error para finalizar (anterior 0.005)\n",
    "lr = 5E-4                # Tasa de aprendizaje (anterior 8E-3)\n",
    "\n",
    "mlp_in.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Época 100: tasa de error de 0.35833333333333334 | MSE promedio 2.1414955776071265\n",
      "Época 200: tasa de error de 0.35833333333333334 | MSE promedio 1.7761339268903695\n",
      "Época 300: tasa de error de 0.35833333333333334 | MSE promedio 1.6296352001050027\n",
      "Época 400: tasa de error de 0.075 | MSE promedio 0.9944763646205769\n",
      "Época 500: tasa de error de 0.08333333333333333 | MSE promedio 0.6157849156453656\n",
      "Finalizó en la época 573 con una tasa de error de 0.008333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Arreglos auxiliares para guardar la evolución del error de la red\n",
    "errorRatePerEpoch = []\n",
    "MMSEPerEpoch = []\n",
    "\n",
    "for epoch in range(NEpoch): # Para cada época\n",
    "    for pattern, yd in zip(mlp_in, Yd): # Para cada patrón en la partición\n",
    "        # Calcular la salida según los pesos actuales (pasada hacia adelante)\n",
    "        (_, y_) = perceptron_simple.eval(pattern)\n",
    "        #print(f'salida{_}={y_}')\n",
    "\n",
    "        # Realizar la propagación hacia atrás donde se calculan los gradientes\n",
    "        # instantáneos (pasada hacia atrás)\n",
    "        perceptron_simple.backward(y_, yd)\n",
    "        \n",
    "        # Actualizar los pesos de la red\n",
    "        perceptron_simple.update(y_, lr)\n",
    "    \n",
    "    # Para la validación se utilizarán solo algunos patrones y se calculará una\n",
    "    # tasa de error, si esta es menor al umbral, se termina el proceso de entrenamiento\n",
    "    # A la vez, se calculará el error cuadrático medio para tener una evolución\n",
    "    # de dicha variable a lo largo de las épocas\n",
    "    errorsAccum_ = 0    # Acumulador de errores\n",
    "    SEAcumm_ = 0        # Acumulador error cuadrático\n",
    "\n",
    "    # [valido con todos los patrones]\n",
    "    for patron, yd in zip(mlp_in, Yd):\n",
    "        # Evaluar el patron\n",
    "        (z_, _) = perceptron_simple.eval(patron)\n",
    "      \n",
    "        #CODIFICACION\n",
    "        if z_[0] == z_.max():\n",
    "            y_ = [1, -1, -1]\n",
    "        elif z_[1] == z_.max():\n",
    "            y_ = [-1, 1, -1]\n",
    "        else:\n",
    "             y_ = [-1, -1, 1]\n",
    "  \n",
    "        # Comparación con la salida deseada y acumulación de errores\n",
    "        errorsAccum_ += int(np.any(np.not_equal(y_, yd)))\n",
    "  \n",
    "        # Cálculo del error cuadrático y acumulación\n",
    "        SEAcumm_ += np.sum(np.square(yd - z_))\n",
    "\n",
    "    # Tasa de error: errores / patrones evaluados\n",
    "    errorRate_ = (errorsAccum_/X.shape[0])\n",
    "    # Guardar la tasa de error de1000 la época\n",
    "    errorRatePerEpoch= np.append(errorRatePerEpoch, [errorRate_])\n",
    "    \n",
    "    # Calcular el error cuadrático medio promedio: MSE / patrones evaluados\n",
    "    MSEMean_= (SEAcumm_/X.shape[0])\n",
    "    # Guardar el error cuadrático medio promedio de la época\n",
    "    MMSEPerEpoch = np.append(MMSEPerEpoch, MSEMean_)\n",
    "\n",
    "    # Si la tasa de error es menor al umbral, termina el proceso de entrenamiento\n",
    "    if (errorRate_ < errorThr):\n",
    "        break\n",
    "\n",
    "    # Cada 100 épocas mostrar el error\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Época {epoch+1}: tasa de error de {errorRatePerEpoch[-1]} | MSE promedio {MMSEPerEpoch[-1]}')\n",
    "   \n",
    "# Imprimir información acerca del entrenamiento\n",
    "print(f'Finalizó en la época {epoch+1} con una tasa de error de {errorRatePerEpoch[-1]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52634da84371cba311ea128a5ea7cdc41ff074b781779e754b270ff9f8153cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
